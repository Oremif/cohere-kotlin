@file:OptIn(ExperimentalSerializationApi::class)

package org.oremif.cohere.api.response

import kotlinx.serialization.ExperimentalSerializationApi
import kotlinx.serialization.Serializable
import kotlinx.serialization.json.JsonClassDiscriminator
import org.oremif.cohere.api.types.Citation
import org.oremif.cohere.api.types.FinishReason
import org.oremif.cohere.api.types.SearchQuery
import org.oremif.cohere.api.types.SearchResult
import org.oremif.cohere.api.types.ToolCall
import org.oremif.cohere.api.types.ToolCallDelta

@Serializable
@JsonClassDiscriminator("event_type")
public sealed interface ChatStreamResponse

/**
 * @property generationId Unique identifier for the generated reply. Useful for submitting feedback.
 */
@JsonClassDiscriminator("stream-start")
public data class StreamStart(val generationId: String) : ChatStreamResponse

/**
 * @property searchQueries Generated search queries, meant to be used as part of the RAG flow.
 */
@JsonClassDiscriminator("search-queries-generation")
public data class SearchQueriesGeneration(
    val searchQueries: List<SearchQuery>,
) : ChatStreamResponse

/**
 * @property searchResults Conducted searches and the ids of documents retrieved from each of them.
 */
@JsonClassDiscriminator("search-results")
public data class SearchResults(
    val searchResults: List<SearchResult>? = null,
    val documents: List<Map<String, String>>? = null,
) : ChatStreamResponse

/**
 * @property text The next batch of text generated by the model.
 */
@JsonClassDiscriminator("text-generation")
public data class TextGeneration(
    val text: String
) : ChatStreamResponse

/**
 * @property citations Citations for the generated reply.
 */
@JsonClassDiscriminator("citation-generation")
public data class CitationGeneration(
    val citations: List<Citation>
) : ChatStreamResponse

/**
 * @property text The text generated related to the tool calls generated
 * @property toolCalls
 */
@JsonClassDiscriminator("tool-calls-generation")
public data class ToolCallsGeneration(
    val text: String? = null,
    val toolCalls: List<ToolCall>
) : ChatStreamResponse

/**
 * @property finishReason
 * * `COMPLETE` - the model sent back a finished reply
 * * `ERROR_LIMIT` - the reply was cut off because the model reached the maximum number of tokens for its context length
 * * `MAX_TOKENS` - the reply was cut off because the model reached the maximum number of tokens specified by the max_tokens parameter
 * - `ERROR` - something went wrong when generating the reply
 * - `ERROR_TOXIC` - the model generated a reply that was deemed toxic
 * @property response The consolidated response from the model.
 * Contains the generated reply and all the other information streamed back in the previous events.
 */
@JsonClassDiscriminator("stream-end")
public data class StreamEnd(
    val finishReason: FinishReason,
    val response: ChatResponse,
) : ChatStreamResponse

/**
 * @property toolCallDelta Contains the chunk of the tool call generation in the stream.
 */
@JsonClassDiscriminator("tool-calls-chunk")
public data class ToolCallsChunk(
    val toolCallDelta: ToolCallDelta
) : ChatStreamResponse